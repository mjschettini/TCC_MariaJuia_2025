{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Script para aplicar a lematização nas bases de palavras classificadas, a fim de gerar uma nova base  com todas as variações de uma palavra, não só sua forma canonica.\n"
      ],
      "metadata": {
        "id": "JKxM5y8KSVE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy pyinflect --quiet\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvZzOj7ORZdB",
        "outputId": "8f667f0f-be52-4d8c-c6d9-098fa473cdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/703.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/703.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m696.3/703.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.5/703.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar o drive para importar o arquivo das pastas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caVkly1pBE_C",
        "outputId": "5eda63ee-5c44-4d8f-f434-273267575d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import spacy\n",
        "import pyinflect\n",
        "\n",
        "# Carrega o modelo spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "0_EE0o-FRZkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Função para gerar formas morfossintáticas (incluindo a palavra original)\n",
        "def get_flexed_forms(word):\n",
        "    doc = nlp(word)\n",
        "    token = doc[0]\n",
        "    forms = set()\n",
        "\n",
        "    # Adiciona a palavra original\n",
        "    forms.add(word)\n",
        "\n",
        "    # Lema\n",
        "    lemma = token.lemma_\n",
        "    forms.add(lemma)\n",
        "\n",
        "    # Plural (mesmo que POS não seja NOUN)\n",
        "    plural = token._.inflect('NNS')\n",
        "    if plural and plural != word:\n",
        "        forms.add(plural)\n",
        "\n",
        "    # Flexões verbais: 3ª pessoa, gerúndio, passado, particípio\n",
        "    for tense in ['VBZ', 'VBG', 'VBD', 'VBN']:\n",
        "        inflected = token._.inflect(tense)\n",
        "        if inflected and inflected != word:\n",
        "            forms.add(inflected)\n",
        "\n",
        "    return sorted(forms)\n",
        "\n",
        "# Caminho da planilha de entrada\n",
        "FILE_KW = \"/content/drive/My Drive/TCC 2025/Base_de_dados/com_ator_saida_palavras_agrupadas_questoes_especificas_sprint_final.csv\"\n",
        "\n",
        "# Lê a planilha\n",
        "df = pd.read_csv(FILE_KW)\n",
        "\n",
        "# Verifica se a coluna 'palavra' existe\n",
        "if 'palavra' not in df.columns:\n",
        "    raise ValueError(\"A coluna 'palavra' não foi encontrada no CSV.\")\n",
        "\n",
        "# Remove colunas desnecessárias\n",
        "colunas_para_remover = ['frequência', 'tipo', 'Validação']\n",
        "df = df.drop(columns=[col for col in colunas_para_remover if col in df.columns])\n",
        "\n",
        "# Converte todas as colunas (exceto 'palavra') para int\n",
        "for col in df.columns:\n",
        "    if col != 'palavra':\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# Lista para armazenar novas linhas\n",
        "linhas_expandidas = []\n",
        "\n",
        "# Inicia a contagem de tempo\n",
        "inicio = time.time()\n",
        "\n",
        "# Gera novas linhas com as formas flexionadas\n",
        "for _, row in df.iterrows():\n",
        "    palavra = row['palavra']\n",
        "    flexoes = get_flexed_forms(palavra)\n",
        "    for forma in flexoes:\n",
        "        nova_linha = row.copy()\n",
        "        nova_linha['palavra'] = forma\n",
        "        linhas_expandidas.append(nova_linha)\n",
        "\n",
        "# Finaliza a contagem de tempo\n",
        "fim = time.time()\n",
        "duracao = fim - inicio\n",
        "\n",
        "# Cria DataFrame final com as novas formas\n",
        "df_expandidas = pd.DataFrame(linhas_expandidas)\n",
        "\n",
        "# Remove linhas duplicadas (considerando todas as colunas)\n",
        "df_expandidas = df_expandidas.drop_duplicates()\n",
        "\n",
        "# Caminho de saída do CSV\n",
        "output_path = \"/content/drive/My Drive/TCC 2025/Base_de_dados/saida_palavras_flexionadas.csv\"\n",
        "df_expandidas.to_csv(output_path, index=False)\n",
        "\n",
        "# Exibe resultado\n",
        "print(f\"Arquivo salvo em: {output_path}\")\n",
        "print(f\"Tempo total de execução: {duracao:.2f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0rIU9cuBHHR",
        "outputId": "2b91a1de-3e8a-44b5-962b-240e1c9e778a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo salvo em: /content/drive/My Drive/TCC 2025/Base_de_dados/saida_palavras_flexionadas.csv\n",
            "Tempo total de execução: 2.28 segundos\n"
          ]
        }
      ]
    }
  ]
}